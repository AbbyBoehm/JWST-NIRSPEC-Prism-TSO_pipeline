import os
from tqdm import tqdm

import numpy as np
import xarray as xr
from astropy.io import fits

from jwst import datamodels as dm

def stitch_files(files, time_step, verbose):
    """Reads all supplied files and stitches them together into a single array.

    Args:
        files (lst of str): filepaths to files that are to be loaded.
        time_ints (bool): whether to report timing with tqdm.
        verbose (int): from 0 to 2. How much logging to do.

    Returns:
        xarray: loaded data.
    """
    # Log.
    if verbose >= 1:
        print("Stitching data files together for post-processing...")
    
    if verbose == 2:
        print("Will stitch together the following files:")
        for i, f in enumerate(files):
            print(i, f)

    # Initialize some empty lists.
    data, err, dq, cdisp, disp, wav = [], [], [], [], [], [] # the data_vars of the xarray
    time = [] # the coords of the xarray
    int_count, flagged = [], [] # the attributes of the array

    # Read in each file.
    for file in tqdm(files,
                     desc = 'Stitching files...',
                     disable=(not time_step)):
        if ".fits" in file:
            # It's Stage 2 output.
            data_i, err_i, int_count_i, wav_i, dq_i, time_i = read_one_datamodel(file)
            wav_i = [wav_i for i in range(time_i.shape[0])]
            # Placeholder empty arrays.
            disp_i, cdisp_i, flagged_i = np.zeros_like(time_i), np.zeros_like(time_i), np.zeros_like(time_i)
        elif ".nc" in file:
            # It's Stage 3 output.
            data_i, err_i, int_count_i, wav_i, dq_i, time_i, disp_i, cdisp_i, flagged_i = read_one_postproc(file)
        # Attributes are appended once.
        int_count.append(int_count_i)
        flagged.append(flagged_i)

        # Datavars and coords are unpacked.
        for i in range(data_i.shape[0]):
            data.append(data_i[i])
            err.append(err_i[i])
            dq.append(dq_i[i])
            time.append(time_i[i])
            disp.append(disp_i[i])
            cdisp.append(cdisp_i[i])
            wav.append(wav_i[i])

    # Now convert to xarray.
    segments = xr.Dataset(data_vars=dict(
                                    data=(["time", "x", "y"], data),
                                    err=(["time", "x", "y"], err),
                                    dq = (["time", "x", "y"], dq),
                                    disp = (["time"], disp),
                                    cdisp = (["time"], cdisp),
                                    wavelengths = (["time", "x", "y"], wav),
                                    ),
                        coords=dict(
                               time = (["time"], time),
                               ),
                        attrs=dict(
                              integrations = int_count,
                              flagged_move = flagged,
                              )
    )

    # Log.
    if verbose >= 1:
        print("Files stitched together into xarray.")
    
    return segments
    
def read_one_datamodel(file):
    """Read one .fits file as a datamodel and return its attributes.

    Args:
        file (str): path to the .fits file you want to read out.

    Returns:
        np.array, np.array, int, np.array, np.array, np.array: the data, errors, integration count, wavelength solution, data quality array, and exposure mid-times.
    """
    with dm.open(file) as f:
         data = f.data
         err = f.err
         int_count = data.shape[0]
         wav = f.wavelength
         dq = f.dq
         t = f.int_times["int_mid_MJD_UTC"]
    return data, err, int_count, wav, dq, t

def read_one_postproc(file):
    """Read one post-processing .nc file and return its attributes.

    Args:
        file (str): path to the .nc file you want to read out.

    Returns:
        np.array, np.array, int, np.array, np.array, np.array, np.array, np.array, np.array: the data, errors, integration count, wavelength solution, data quality array, exposure mid-times, cross/dispersion positions, and frame numbers flagged for motion.
    """
    segment = xr.open_dataset(file)
    data = segment.data.values
    err = segment.err.values
    int_count = segment.integrations
    wav = segment.wavelengths.values
    dq = segment.dq.values
    time = segment.time.values
    disp = segment.disp.values
    cdisp = segment.disp.values
    flagged = segment.flagged
    return data, err, int_count, wav, dq, time, disp, cdisp, flagged

def save_s3_output(segments, disp_pos, cdisp_pos, moved_ints, outfiles, outdir):
    """Saves an xarray for every cleaned segment in the stitched-together files.

    Args:
        segments (xarray): the xarray generated by stitch_files.
        disp_pos (list): dispersion positions. Could be an empty list.
        cdisp_pos (list): cross-dispersion positions. Could be an empty list.
        moved_ints (list): integrations flagged for movement. Could be an empty list.
        outfiles (list of str): names for each output file.
        outdir (str): directory to save the output files to.
    """
    # For every segment in the array, we need to break it up.
    int_left = 0
    int_right = 0
    for i, (ints, outfile) in enumerate(zip(segments.integrations, outfiles)):
        # Get the next limit.
        int_right += ints

        # Snip just the data that we need.
        data = segments.data.values[int_left:int_right,:,:]
        err = segments.err.values[int_left:int_right,:,:]
        dq = segments.dq.values[int_left:int_right,:,:]
        time = segments.time.values[int_left:int_right]
        wavelengths = segments.wavelengths.values[int_left:int_right,:,:]

        # Plus the new tracking data, if there is any.
        disp = []
        if disp_pos:
            disp = disp_pos[int_left:int_right]
        cdisp = []
        if cdisp_pos:
            cdisp = cdisp_pos[int_left:int_right]

        # If a moved integration was in this data, report it.
        moved_int = []
        if moved_ints:
            moved_int = sorted([j for j in moved_ints if (j >= int_left and j <= int_right)])

        # Now convert to xarray.
        segment = xr.Dataset(data_vars=dict(
                                    data=(["time", "x", "y"], data),
                                    err=(["time", "x", "y"], err),
                                    dq = (["time", "x", "y"], dq),
                                    disp = (["time"], disp),
                                    cdisp = (["time"], cdisp),
                                    wavelengths = (["time", "x", "y"], wavelengths),
                                    ),
                        coords=dict(
                               time = (["time"], time),
                               ),
                        attrs=dict(
                              integrations = ints,
                              flagged_move = moved_int,
                              )
        )

        # And save that segment as a file.
        segment.to_netcdf(os.path.join(outdir, '{}.nc'.format(outfile)))

        # Advance int_left.
        int_left = int_right

def save_s4_output(oneD_spec, oneD_err, time, wav_sols, shifts, outfile, outdir):
    """Saves an xarray for the extracted 1D spectra.

    Args:
        oneD_spec (np.array): extracted 1D spectra.
        oneD_err (np.array): extracted uncertainties on 1D spectra.
        time (np.array): mid-exposure times for each 1D spectrum.
        wav_sols (np.array): wavelength solutions for the 1D spectra.
        shifts (np.array): cross-correlation shfits for 1D spectra.
        outfile (str): name of the output file.
        outdir (str): directory to which the .nc file will be saved to.
    """
    # Convert to xarray.
    spectra = xr.Dataset(data_vars=dict(
                                    spectrum=(["time", "wavelength"], oneD_spec),
                                    err=(["time", "wavelength"], oneD_err),
                                    waves=(["time", "wavelength"],wav_sols),
                                    shifts=(["time"],shifts),
                                    ),
                        coords=dict(
                               time = (["time"], time),
                               ),
                        attrs=dict(
                              )
    )

    # And save that segment as a file.
    spectra.to_netcdf(os.path.join(outdir, '{}.nc'.format(outfile)))